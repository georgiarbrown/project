{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7928b5c7",
   "metadata": {},
   "source": [
    "# RAG Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605d8997",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "278f13c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "from pinecone import Pinecone\n",
    "\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, SemanticSimilarity\n",
    "\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2db5542",
   "metadata": {},
   "source": [
    "###Â Setting API Keys & Initialising Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86c71391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting API Keys\n",
    "OPENAI_API_KEY = 'your-openai-api-key-here'\n",
    "PINECONE_API_KEY = 'your-pinecone-api-key-here'\n",
    "\n",
    "os.environ['PINECONE_API_KEY'] = PINECONE_API_KEY\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "\n",
    "# Initialising Pinecone\n",
    "pc = Pinecone(api_key = PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5877d2c",
   "metadata": {},
   "source": [
    "### Loading Ground Truth & Splitting into Train/Val/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36c88812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ground truth papers: 20\n",
      "Train: 10 papers\n",
      "Val: 5 papers\n",
      "Test: 5 papers\n"
     ]
    }
   ],
   "source": [
    "# Loading ground truth dataset\n",
    "ground_truth_df = pd.read_csv('ground_truth_dataset.csv')\n",
    "\n",
    "# Getting unique paper names\n",
    "unique_papers = ground_truth_df['filename'].unique()\n",
    "print(f\"Total ground truth papers: {len(unique_papers)}\")\n",
    "\n",
    "# Splitting papers into train/test/val\n",
    "train_papers, temp_papers = train_test_split(unique_papers, test_size=0.5, random_state=42)\n",
    "val_papers, test_papers = train_test_split(temp_papers, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Train: {len(train_papers)} papers\")\n",
    "print(f\"Val: {len(val_papers)} papers\")  \n",
    "print(f\"Test: {len(test_papers)} papers\")\n",
    "\n",
    "# Creating separate dataframes\n",
    "train_df = ground_truth_df[ground_truth_df['filename'].isin(train_papers)]\n",
    "val_df = ground_truth_df[ground_truth_df['filename'].isin(val_papers)]\n",
    "test_df = ground_truth_df[ground_truth_df['filename'].isin(test_papers)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadf5f19",
   "metadata": {},
   "source": [
    "### Preprocessing and Loading the PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eadcdde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'References\\s*\\n[\\s\\S]*?(?=\\n[A-Z][a-z]+\\s*\\n|$)', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\[\\d+(?:,\\s*\\d+)*\\]', '', text)\n",
    "    text = re.sub(r'\\(\\w+\\s+et\\s+al\\.,?\\s*\\d{4}\\)', '', text)\n",
    "    text = re.sub(r'\\(\\w+\\s+and\\s+\\w+,?\\s*\\d{4}\\)', '', text)\n",
    "    text = re.sub(r'(Figure|Fig\\.|Table)\\s+\\d+[:\\.].*?(?=\\n)', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'https?://\\S+', '', text)\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "    text = re.sub(r' {2,}', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "# Defining the loading function\n",
    "def load_docs(paper_list, folder='biochar_papers/'):\n",
    "    docs = []\n",
    "    for filename in paper_list:\n",
    "        path = os.path.join(folder, filename)\n",
    "        if os.path.exists(path):\n",
    "            pages = PyPDFLoader(path).load()\n",
    "            full_text = ' '.join([p.page_content for p in pages])\n",
    "            clean = preprocess_text(full_text)\n",
    "            docs.append(Document(page_content=clean, metadata={'source': filename}))\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b1fb93",
   "metadata": {},
   "source": [
    "### Chunking and Embedding Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac4e3fac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tw/nvhztmg5021748_6hl30s_v40000gn/T/ipykernel_70241/759482409.py:5: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
      "Ignoring wrong pointing object 5 0 (offset 0)\n",
      "Ignoring wrong pointing object 7 0 (offset 0)\n",
      "Ignoring wrong pointing object 9 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "Ignoring wrong pointing object 41 0 (offset 0)\n",
      "Ignoring wrong pointing object 43 0 (offset 0)\n",
      "Ignoring wrong pointing object 45 0 (offset 0)\n",
      "Ignoring wrong pointing object 77 0 (offset 0)\n",
      "Ignoring wrong pointing object 79 0 (offset 0)\n",
      "Ignoring wrong pointing object 81 0 (offset 0)\n",
      "Ignoring wrong pointing object 107 0 (offset 0)\n",
      "Ignoring wrong pointing object 109 0 (offset 0)\n",
      "Ignoring wrong pointing object 111 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "# Splitting documents\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "# Initialising embeddings\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Creating a vector store with all biochar papers\n",
    "all_papers = os.listdir('biochar_papers/')\n",
    "all_papers = [f for f in all_papers if f.endswith('.pdf')]\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "all_docs = load_docs(all_papers)\n",
    "all_chunks = splitter.split_documents(all_docs)\n",
    "\n",
    "index = pc.Index(\"biochar-final\")\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embeddings)\n",
    "\n",
    "for i in range(0, len(all_chunks), batch_size):\n",
    "    batch = all_chunks[i:i + batch_size]\n",
    "    vector_store.add_documents(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70114dd1",
   "metadata": {},
   "source": [
    "### Defining Extraction Queries & Prompts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c54905fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining extraction queries\n",
    "extraction_queries = [\n",
    "    \"What crop yield and soil quality improvements did biochar provide in this study, and under what specific conditions (soil pH, texture, climate)?\",\n",
    "    \"What water-related benefits (retention, drought resilience, irrigation needs) were observed, and in which soil types or climate conditions?\",\n",
    "    \"What economic or social co-benefits were reported or discussed (income, poverty, food security), including indirect benefits from agricultural improvements?\",\n",
    "    \"What environmental impacts (GHG emissions, carbon sequestration, nutrient leaching) were measured?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8f5d12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining two prompts to test\n",
    "prompt_minimal = \"\"\"Extract study findings about biochar co-benefits.\n",
    "\n",
    "- Focus on specific co-benefits\n",
    "- Include conditions and numbers if given\n",
    "- Exclude biochar type or rate\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "If not mentioned, say \"not mentioned in this study\".\"\"\"\n",
    "\n",
    "prompt_detailed = \"\"\"You are an environmental research assistant tasked with extracting findings from this \n",
    "document about biochar co-benefits.\n",
    "\n",
    "Instructions:\n",
    "- Focus on specific co-benefits (e.g. yield improvement, water retention, poverty reduction)\n",
    "- Include both observed benefits from field trials and discussed potential benefits\n",
    "- Review papers that synthesise benefits across multiple studies should report the synthesised findings\n",
    "- Include conditions under which these benefits occurred (soil pH, texture, climate, farmer type)\n",
    "- Combine benefits with their conditions (e.g. \"yield improved in acidic soils\")\n",
    "- Include numbers when available (e.g. 30% yield increase, pH 5.2)\n",
    "- For socioeconomic benefits, include implied outcomes (e.g. \"yield increases expected to improve food security\")\n",
    "- DO NOT mention the type of biochar or application rate of the biochar\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "If no specific evidence addresses this question, say \"not mentioned in this study\".\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97dee03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining extraction function\n",
    "def extract_direct_answer(vector_store, query, source_doc, k, prompt_template):\n",
    "    llm = ChatOpenAI(temperature=0, model_name='gpt-4')\n",
    "    retriever = vector_store.as_retriever(search_kwargs={\"k\": k, \"filter\": {\"source\": source_doc}})\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=True)\n",
    "    full_prompt = prompt_template.replace(\"{query}\", query)\n",
    "    response = qa({\"query\": full_prompt})\n",
    "    return {\n",
    "        \"answer\": response[\"result\"],\n",
    "        \"contexts\": [doc.page_content for doc in response[\"source_documents\"]]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e505ed2",
   "metadata": {},
   "source": [
    "### Evaluation Loop for Prompt Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5492f16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tw/nvhztmg5021748_6hl30s_v40000gn/T/ipykernel_70241/1892636737.py:7: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa({\"query\": full_prompt})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea7e8ebfc8c42e19b8ea1a12a45dedc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt One Results:\n",
      "  Faithfulness: 0.641\n",
      "  Semantic Similarity: 0.892\n",
      "  Samples: 40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e6f222c01b24171a6adb81c13cd0b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt Two Results:\n",
      "  Faithfulness: 0.797\n",
      "  Semantic Similarity: 0.893\n",
      "  Samples: 40\n"
     ]
    }
   ],
   "source": [
    "# Testing prompts on training data\n",
    "def evaluate_prompt_on_split(split_df, prompt_template, prompt_name, k=5):\n",
    "    eval_data = []\n",
    "    \n",
    "    for _, row in split_df.iterrows():\n",
    "        if row['found'].lower() == 'yes':\n",
    "            result = extract_direct_answer(vector_store, row['query'], row['filename'], k, prompt_template)\n",
    "            \n",
    "            eval_data.append({\n",
    "                'question': row['query'],\n",
    "                'answer': result['answer'],\n",
    "                'contexts': result['contexts'],\n",
    "                'reference': row['expected_answer']})\n",
    "    \n",
    "    dataset = Dataset.from_list(eval_data)\n",
    "    results = evaluate(dataset, metrics=[faithfulness, SemanticSimilarity()])\n",
    "    \n",
    "    avg_results = {\n",
    "        'faithfulness': np.mean(results['faithfulness']),\n",
    "        'semantic_similarity': np.mean(results['semantic_similarity']),\n",
    "        'n_samples': len(eval_data)}\n",
    "    \n",
    "    print(f\"\\n{prompt_name} Results:\")\n",
    "    print(f\"  Faithfulness: {avg_results['faithfulness']:.3f}\")\n",
    "    print(f\"  Semantic Similarity: {avg_results['semantic_similarity']:.3f}\")\n",
    "    print(f\"  Samples: {avg_results['n_samples']}\")\n",
    "    \n",
    "    return avg_results\n",
    "\n",
    "# Testing both prompts on training data\n",
    "train_results_minimal = evaluate_prompt_on_split(train_df, prompt_minimal, \"Prompt One\", k=5)\n",
    "train_results_detailed = evaluate_prompt_on_split(train_df, prompt_detailed, \"Prompt Two\", k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb89e47",
   "metadata": {},
   "source": [
    "### Tuning K on Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "696668b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842ad0c1fefa493f8fbba75f0e3f80a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=3: Faithfulness = 0.679, Semantic Similarity = 0.874\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd896ffb9230429ea5ac44b5bf2a6c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5: Faithfulness = 0.751, Semantic Similarity = 0.862\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6e40a6d09e4980afa7acfd959acbdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=7: Faithfulness = 0.804, Semantic Similarity = 0.866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2847a80e8604b3b827dae0a9ec73a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=10: Faithfulness = 0.806, Semantic Similarity = 0.863\n"
     ]
    }
   ],
   "source": [
    "# Selecting prompt to use\n",
    "best_prompt = prompt_detailed\n",
    "\n",
    "k_values = [3, 5, 7, 10]\n",
    "validation_results = {}\n",
    "\n",
    "for k in k_values:\n",
    "    eval_data = []\n",
    "    \n",
    "    for _, row in val_df.iterrows():\n",
    "        if row['found'].lower() == 'yes':\n",
    "            result = extract_direct_answer(vector_store, row['query'], row['filename'], k, best_prompt)\n",
    "            \n",
    "            eval_data.append({\n",
    "                'question': row['query'],\n",
    "                'answer': result['answer'],\n",
    "                'contexts': result['contexts'],\n",
    "                'reference': row['expected_answer']})\n",
    "    \n",
    "    dataset = Dataset.from_list(eval_data)\n",
    "    results = evaluate(dataset, metrics=[faithfulness, SemanticSimilarity()])\n",
    "    \n",
    "    validation_results[k] = {\n",
    "        'faithfulness': np.mean(results['faithfulness']),\n",
    "        'semantic_similarity': np.mean(results['semantic_similarity'])}\n",
    "    \n",
    "    print(f\"k={k}: Faithfulness = {validation_results[k]['faithfulness']:.3f}, Semantic Similarity = {validation_results[k]['semantic_similarity']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9011d257",
   "metadata": {},
   "source": [
    "### Testing with Best K and Best Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7337f7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef19fd7fb2cd4e4ebf981e239842daa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Faithfulness: 0.835\n",
      "  Semantic Similarity: 0.885\n",
      "  Samples: 20\n"
     ]
    }
   ],
   "source": [
    "# Selecting k value to use \n",
    "best_k = 7\n",
    "\n",
    "test_eval_data = []\n",
    "\n",
    "for _, row in test_df.iterrows():\n",
    "    if row['found'].lower() == 'yes':\n",
    "        result = extract_direct_answer(vector_store, row['query'], row['filename'], best_k, best_prompt)\n",
    "        \n",
    "        test_eval_data.append({\n",
    "            'question': row['query'],\n",
    "            'answer': result['answer'],\n",
    "            'contexts': result['contexts'],\n",
    "            'reference': row['expected_answer']})\n",
    "\n",
    "test_dataset = Dataset.from_list(test_eval_data)\n",
    "test_results = evaluate(test_dataset, metrics=[faithfulness, SemanticSimilarity()])\n",
    "\n",
    "print(f\"  Faithfulness: {np.mean(test_results['faithfulness']):.3f}\")\n",
    "print(f\"  Semantic Similarity: {np.mean(test_results['semantic_similarity']):.3f}\")\n",
    "print(f\"  Samples: {len(test_eval_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab60f622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAPER 1: tisserant_2019_global.pdf\n",
      "\n",
      "Query: What crop yield and soil quality improvements did biochar provide in this study, and under what specific conditions (soil pH, texture, climate)?\n",
      "\n",
      "Ground Truth: Biochar increased crop yields by an average of 25% in tropical soils, especially those that are acidic, highly weathered, and low in CEC. Effects in temperate soils were mostly neutral or negative. \n",
      "\n",
      "Model Extracted: Biochar provided several improvements to crop yield and soil quality in this study. In highly weathered, acidic soils with low cation exchange capacity (CEC), typically found in tropical regions, biochar application resulted in a positive response in terms of yield. An average increase in yield of 25% was observed in these tropical soils. However, biochar had no or very little positive or even negative effects in temperate soil. \n",
      "\n",
      "Increased soil moisture, which can be a result of biochar application, can increase yield in temperate regions that have less weathered soils and higher agricultural inputs. Negative yield responses were mostly observed under alkaline soil conditions, which potentially limit phosphorus supply to plants. \n",
      "\n",
      "Biochar's effect on soil water retention and plant water availability may represent an interesting adaptation to climate change. This effect is positively correlated to the level of precipitation. \n",
      "\n",
      "In terms of soil quality, biochar can increase or decrease the risk of soil degradation or help reclaim degraded soil. These effects are important for food security. \n",
      "\n",
      "In tropical and subtropical regions with weathered soils, the yield response to biochar is more pronounced. Higher soil water retention may also provide adaptation to climate change in some of the most vulnerable regions. Higher yield and retention of soil fertility may also help mitigate shifting agriculture practices in tropical forests. \n",
      "\n",
      "However, the study also notes that the long-term aging and effects of biochar on soils are not fully understood.\n",
      "\n",
      "Query: What water-related benefits (retention, drought resilience, irrigation needs) were observed, and in which soil types or climate conditions?\n",
      "\n",
      "Ground Truth: Biochar improved soil water retention and plant available water, especially in coarse soils and under dry conditions.  It enhanced drought resilience and evapotranspiration. \n",
      "\n",
      "Model Extracted: The document mentions that biochar has a positive effect on soil water retention and plant water availability, which could be an adaptation to climate change. This is particularly beneficial in highly weathered soils that are acidic with low cation exchange capacity (CEC) and receive little water, conditions that are widespread in tropical and subtropical regions. The document also mentions that higher soil water retention may provide adaptation to climate change in some of the most vulnerable regions. \n",
      "\n",
      "Biochar's effects on the soil water cycle also allow for increasing plant water availability. A minimum of 20â25 t biochar per hectare may be required to effectively increase soil available water capacity and to significantly modify soil hydraulic conductivity. \n",
      "\n",
      "Biochar application can also affect soil temperature via several interacting mechanisms such as increased soil moisture. Fischer and colleagues estimated that biochar increases evapotranspiration by about 5% in a coarse soil at about 150 t biochar/ha, as more water entering soil is stored and available to plants for evapotranspiration. Koide and colleagues found an increase in 0.8â2.7 days of transpiration after biochar addition. Increased evapotranspiration would have a cooling effect. \n",
      "\n",
      "However, the document also mentions that the long-term aging and effects of biochar on soils are not fully understood.\n",
      "\n",
      "Query: What economic or social co-benefits were reported or discussed (income, poverty, food security), including indirect benefits from agricultural improvements?\n",
      "\n",
      "Ground Truth: Yield increases in degraded soils are expected to improve food security and reduce land degradation risks. Increased fertiliser efficiency may lower input costs for farmers. Higher yields in nutrient-poor tropical soils may reduce poverty risks. Reduced erosion may help maintain land productivity, \n",
      "\n",
      "Model Extracted: The document discusses several economic and social co-benefits of biochar. One of the key benefits is the potential improvement in agricultural yield, which is often cited as an important co-benefit of its carbon sequestration. This could indirectly enhance food security and increase income for farmers. However, it's also noted that some negative yield responses have been observed. \n",
      "\n",
      "The yield response to biochar is more pronounced in tropical and subtropical regions with weathered soils. This suggests that biochar may provide important social benefits for some of the most vulnerable farmers in these regions. \n",
      "\n",
      "Higher soil water retention, another benefit of biochar, may also provide adaptation to climate change in some of the most vulnerable regions. This could potentially reduce the risk of crop failure and thereby improve food security and income stability for farmers in these regions. \n",
      "\n",
      "Furthermore, higher yield and retention of soil fertility may help mitigate shifting agriculture practices in tropical forests, which is responsible for about 24% of forest disturbances. This could potentially reduce deforestation and its associated social and economic impacts. \n",
      "\n",
      "However, the document also warns of potential adverse side effects on food security or natural ecosystems due to the expansion of dedicated biomass plantations for biochar feedstocks at the expense of croplands or forests. This suggests that the economic and social benefits of biochar could be offset by negative impacts on food production and forest ecosystems if not managed properly. \n",
      "\n",
      "The document does not provide specific numbers on the extent of yield improvement, income increase, or poverty reduction associated with biochar.\n",
      "\n",
      "Query: What environmental impacts (GHG emissions, carbon sequestration, nutrient leaching) were measured?\n",
      "\n",
      "Ground Truth: Biochar reduced N2O emissions by 32-38% on average and NOX by 47-67%. Nitrate leaching reduced by 12-29%. Soil carbon stability improved especially in acidic, dyr sils with high clay content. Carbon sequestration ranged from 0.04 to 1.67 tCO2 -eq. \n",
      "\n",
      "Model Extracted: The document discusses the environmental impacts of biochar in terms of greenhouse gas (GHG) emissions, carbon sequestration, and nutrient leaching. \n",
      "\n",
      "Positive values in the study's Figure 3 correspond to net emissions of GHGs, while negative values represent net avoided emissions of GHGs or sequestration of carbon. This indicates that biochar systems can either contribute to or mitigate GHG emissions, depending on various factors such as the life-cycle stages of the biochar system, including supply chain and pyrolysis, avoided emissions from coproducts, carbon sequestration in soils, and effects to soil emissions.\n",
      "\n",
      "In terms of carbon sequestration, biochar aims at mitigating climate change by capturing and storing atmospheric carbon in recalcitrant form. The combined effect of increased soil organic carbon (SOC) stability and biomass yield after biochar application may also lead to an increase in the stock of soil carbon in agroecosystems.\n",
      "\n",
      "The document also mentions that the collection and transport of biomass residues, which are used in the production of biochar, require energy and are associated with GHG emissions. However, the collection of residues also avoids GHG emissions due to their decomposition, at the cost of potential losses of SOC.\n",
      "\n",
      "The combustion of pyrolysis gas, a byproduct of the biochar production process, leads to emissions of CO2, SO2, NOx, and N2O. \n",
      "\n",
      "The document does not provide specific information on the impact of biochar on nutrient leaching.\n",
      "PAPER 2: krause_2018_switzerland.pdf\n",
      "\n",
      "Query: What crop yield and soil quality improvements did biochar provide in this study, and under what specific conditions (soil pH, texture, climate)?\n",
      "\n",
      "Ground Truth: The study reported that biochar application inÂ temperate soilsÂ of Switzerland did not consistently improve crop yields but did enhanceÂ soil structure,Â cation exchange capacity, andÂ microbial biomass, particularly in soils withÂ low initial fertility. It noted that yield effects in temperate climates wereÂ variable or neutral, with some benefits occurring underÂ depleted soil conditions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Extracted: This study does not provide specific information on crop yield improvements due to biochar. However, it does mention that biochar addition to soil can increase soil pH. In this particular study, liming treatment and biochar addition resulted in an increase of soil pH by 0.4 pH units on average. The soil pH in the control treatment was 6.3 on average. The study was conducted on a clay loam soil with a particle size distribution of 37% sand, 27% silt, and 36% clay, under a temperate climate with a mean annual temperature of 9.4 Â°C and mean annual precipitation of 1054 mm. The study also found that biochar amendment reduced N2O emissions by 52% compared to the control, suggesting an improvement in soil quality.\n",
      "\n",
      "Query: What water-related benefits (retention, drought resilience, irrigation needs) were observed, and in which soil types or climate conditions?\n",
      "\n",
      "Ground Truth: Biochar contributed to increasedÂ soil water retentionÂ and improvedÂ soil porosity, particularly inÂ light-textured soils, helping to buffer water stress during dry periods in aÂ temperate climate.\n",
      "\n",
      "Model Extracted: The document does not mention any water-related benefits such as retention, drought resilience, or irrigation needs associated with biochar use.\n",
      "\n",
      "Query: What economic or social co-benefits were reported or discussed (income, poverty, food security), including indirect benefits from agricultural improvements?\n",
      "\n",
      "Ground Truth: Economic benefits were discussed in relation to long-term soil health improvement and reduced fertiliser needs, which may lower production costs. The study also referenced potential policy incentives and market value for biochar-related carbon credits, though no direct poverty or food security impacts were measured.\n",
      "\n",
      "Model Extracted: Not mentioned in this study.\n",
      "\n",
      "Query: What environmental impacts (GHG emissions, carbon sequestration, nutrient leaching) were measured?\n",
      "\n",
      "Ground Truth: The study confirmed that biochar contributed toÂ carbon sequestrationÂ by adding stable carbon to the soil andÂ reduced nitrate leachingÂ in some trials. It noted thatÂ greenhouse gas emissionsÂ (e.g., N2O) were not consistently reduced across all field sites, highlighting variability in temperate conditions.\n",
      "\n",
      "Model Extracted: The study found that biochar treatment resulted in a decrease in N2O emissions by 52% compared to the control. This was measured across a vegetation period. The study also found that biochar treatment increased soil pH by 0.4 units on average, which is suggested to be a key mechanism in reducing N2O emissions. However, the study did not report on other greenhouse gas emissions, carbon sequestration, or nutrient leaching.\n"
     ]
    }
   ],
   "source": [
    "# Comparing ground truth vs model extraction\n",
    "test_papers_list = test_df[test_df['found'] == 'yes']['filename'].unique()\n",
    "random_papers = np.random.choice(test_papers_list, size=min(2, len(test_papers_list)), replace=False)\n",
    "\n",
    "for paper_num, paper in enumerate(random_papers, 1):\n",
    "    print(f\"PAPER {paper_num}: {paper}\")\n",
    "    \n",
    "    paper_rows = test_df[test_df['filename'] == paper]\n",
    "    \n",
    "    for _, row in paper_rows.iterrows():\n",
    "        print(f\"\\nQuery: {row['query']}\")\n",
    "        print(f\"\\nGround Truth: {row['expected_answer']}\")\n",
    "        \n",
    "        extracted = extract_direct_answer(vector_store, row['query'], row['filename'], best_k, best_prompt)\n",
    "        print(f\"\\nModel Extracted: {extracted['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28f4e2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             source_document  \\\n",
      "0          wang_2019_usa.pdf   \n",
      "1      yeboah_2020_ghana.pdf   \n",
      "2    shoudho_2024_global.pdf   \n",
      "3  juraszeck_2021_europe.pdf   \n",
      "4    katterer_2019_kenya.pdf   \n",
      "\n",
      "                                    yield_conditions  \\\n",
      "0  The study does not provide specific evidence o...   \n",
      "1  The study found that biochar improved the grow...   \n",
      "2  The study found that the utilization of biocha...   \n",
      "3  The study found that biochar application incre...   \n",
      "4  The study found that biochar significantly imp...   \n",
      "\n",
      "                                      water_benefits  \\\n",
      "0  The study found that biochar can improve soil ...   \n",
      "1  The study observed that biochar improves water...   \n",
      "2  The document mentions that biochar enhances so...   \n",
      "3  The study observed that biochar application si...   \n",
      "4  The study observed that the application of bio...   \n",
      "\n",
      "                              socioeconomic_benefits  \\\n",
      "0                       Not mentioned in this study.   \n",
      "1                       Not mentioned in this study.   \n",
      "2  The document discusses several economic and so...   \n",
      "3                       Not mentioned in this study.   \n",
      "4  The study does not directly mention specific e...   \n",
      "\n",
      "                               environmental_impacts  \n",
      "0  The study mentions that soil amendments, such ...  \n",
      "1  The environmental impacts such as GHG emission...  \n",
      "2  The document mentions several environmental im...  \n",
      "3  The environmental impacts such as GHG emission...  \n",
      "4  The study mentions that biochar application ca...  \n"
     ]
    }
   ],
   "source": [
    "# Extracting from all papers\n",
    "all_extractions = []\n",
    "\n",
    "for i, filename in enumerate(all_papers):\n",
    "    \n",
    "    paper_extractions = {'source_document': filename}\n",
    "    \n",
    "    for query in extraction_queries:\n",
    "        result = extract_direct_answer(vector_store, query, filename, best_k, best_prompt)\n",
    "        paper_extractions[query] = result['answer']\n",
    "    \n",
    "    all_extractions.append(paper_extractions)\n",
    "\n",
    "# Creating dataframe\n",
    "extractions_df = pd.DataFrame(all_extractions)\n",
    "\n",
    "# Renaming columns\n",
    "extractions_df = extractions_df.rename(columns={\n",
    "    extraction_queries[0]: 'yield_conditions',\n",
    "    extraction_queries[1]: 'water_benefits',\n",
    "    extraction_queries[2]: 'socioeconomic_benefits',\n",
    "    extraction_queries[3]: 'environmental_impacts'})\n",
    "\n",
    "# Saving final results\n",
    "extractions_df.to_csv('biochar_cobenefit_extractions.csv', index=False)\n",
    "\n",
    "# Previewing \n",
    "print(extractions_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fb14b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
